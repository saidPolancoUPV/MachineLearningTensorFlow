{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "breast_cancer = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "path = tf.keras.utils.get_file(breast_cancer.split(\"/\")[-1], breast_cancer)\n",
    "\n",
    "columns = ['sample_code', 'clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity', 'marginal_adhesion', 'single_epithelial_cell_size',\n",
    "           'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class']\n",
    "data = pd.read_csv(path, header=None, names=columns, na_values=[np.nan, '?'])\n",
    "data = data.fillna(data.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_code</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>cell_size_uniformity</th>\n",
       "      <th>cell_shape_uniformity</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>single_epithelial_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_code  clump_thickness  cell_size_uniformity  cell_shape_uniformity  \\\n",
       "0      1000025                5                     1                      1   \n",
       "1      1002945                5                     4                      4   \n",
       "2      1015425                3                     1                      1   \n",
       "3      1016277                6                     8                      8   \n",
       "4      1017023                4                     1                      1   \n",
       "\n",
       "   marginal_adhesion  single_epithelial_cell_size  bare_nuclei  \\\n",
       "0                  1                            2          1.0   \n",
       "1                  5                            7         10.0   \n",
       "2                  1                            2          2.0   \n",
       "3                  1                            3          4.0   \n",
       "4                  3                            2          1.0   \n",
       "\n",
       "   bland_chromatin  normal_nucleoli  mitoses  class  \n",
       "0                3                1        1      2  \n",
       "1                3                2        1      2  \n",
       "2                3                1        1      2  \n",
       "3                3                7        1      2  \n",
       "4                3                1        1      2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "train = data.sample(frac=0.8).copy()\n",
    "y_train = (train['class']==4).astype(int)\n",
    "train.drop(['sample_code', 'class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = data.loc[~data.index.isin(train.index)].copy()\n",
    "y_test = (test['class']==4).astype(int)\n",
    "test.drop(['sample_code', 'class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>cell_size_uniformity</th>\n",
       "      <th>cell_shape_uniformity</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>single_epithelial_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  cell_size_uniformity  cell_shape_uniformity  \\\n",
       "584                5                     1                      1   \n",
       "417                1                     1                      1   \n",
       "606                4                     1                      1   \n",
       "349                4                     2                      3   \n",
       "134                3                     1                      1   \n",
       "\n",
       "     marginal_adhesion  single_epithelial_cell_size  bare_nuclei  \\\n",
       "584                  6                            3          1.0   \n",
       "417                  1                            2          1.0   \n",
       "606                  2                            2          1.0   \n",
       "349                  5                            3          8.0   \n",
       "134                  1                            3          1.0   \n",
       "\n",
       "     bland_chromatin  normal_nucleoli  mitoses  \n",
       "584                1                1        1  \n",
       "417                2                1        1  \n",
       "606                1                1        1  \n",
       "349                7                6        1  \n",
       "134                2                1        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584    0\n",
       "417    0\n",
       "606    0\n",
       "349    1\n",
       "134    0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_logreg(feature_columns, feature_layer_inputs, optimizer, loss='binary_crossentropy', metrics=['accuracy'], l2=0.01):\n",
    "    regularizer = keras.regularizers.l2(l2)\n",
    "\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, kernel_initializer='normal',\n",
    "                                kernel_regularizer=regularizer,\n",
    "                                activation='sigmoid')(norm)\n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def define_feature_columns_layers(data_df, categorical_cols, numeric_cols):\n",
    "    feature_columns = []\n",
    "    feature_layer_inputs = {}\n",
    "\n",
    "    for feature_name in numeric_cols:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name)\n",
    "\n",
    "    for feature_name in categorical_cols:\n",
    "        vocabulary = data_df[feature_name].unique()\n",
    "        cat = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "        cat_one_hot = tf.feature_column.indicator_column(cat)\n",
    "        feature_columns.append(cat_one_hot)\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name, dtype=tf.int32)\n",
    "\n",
    "    return feature_columns, feature_layer_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def canned_keras(model):\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    keras_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=model_dir)\n",
    "    return keras_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp505sf4re', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "numeric_cols = ['clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity', 'marginal_adhesion', 'single_epithelial_cell_size',\n",
    "                'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.007)\n",
    "model = create_logreg(feature_columns, feature_layer_inputs, optimizer, l2=0.01)\n",
    "\n",
    "estimator = canned_keras(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=256):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_input_fn = make_input_fn(train, y_train, num_epochs=300, batch_size=32)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmp505sf4re/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: /tmp/tmp505sf4re/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp505sf4re/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.75158775, step = 0\n",
      "INFO:tensorflow:global_step/sec: 231.039\n",
      "INFO:tensorflow:loss = 0.6875802, step = 100 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.758\n",
      "INFO:tensorflow:loss = 0.68792486, step = 200 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.916\n",
      "INFO:tensorflow:loss = 0.6541245, step = 300 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.676\n",
      "INFO:tensorflow:loss = 0.6076306, step = 400 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.281\n",
      "INFO:tensorflow:loss = 0.58691823, step = 500 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.173\n",
      "INFO:tensorflow:loss = 0.57006896, step = 600 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.982\n",
      "INFO:tensorflow:loss = 0.5306612, step = 700 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.834\n",
      "INFO:tensorflow:loss = 0.51997733, step = 800 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.415\n",
      "INFO:tensorflow:loss = 0.42419618, step = 900 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.237\n",
      "INFO:tensorflow:loss = 0.47951835, step = 1000 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.454\n",
      "INFO:tensorflow:loss = 0.40535358, step = 1100 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.469\n",
      "INFO:tensorflow:loss = 0.3018583, step = 1200 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.417\n",
      "INFO:tensorflow:loss = 0.37845996, step = 1300 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.332\n",
      "INFO:tensorflow:loss = 0.2558911, step = 1400 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.757\n",
      "INFO:tensorflow:loss = 0.26917577, step = 1500 (0.294 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1523 vs previous value: 1523. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 317.092\n",
      "INFO:tensorflow:loss = 0.27227747, step = 1600 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.154\n",
      "INFO:tensorflow:loss = 0.24263483, step = 1700 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.294\n",
      "INFO:tensorflow:loss = 0.22539857, step = 1800 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.97\n",
      "INFO:tensorflow:loss = 0.29240337, step = 1900 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.148\n",
      "INFO:tensorflow:loss = 0.23886365, step = 2000 (0.249 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2004 vs previous value: 2004. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2047 vs previous value: 2047. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 334.424\n",
      "INFO:tensorflow:loss = 0.17876157, step = 2100 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.114\n",
      "INFO:tensorflow:loss = 0.21309687, step = 2200 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.51\n",
      "INFO:tensorflow:loss = 0.20924786, step = 2300 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.269\n",
      "INFO:tensorflow:loss = 0.26430884, step = 2400 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.286\n",
      "INFO:tensorflow:loss = 0.19500385, step = 2500 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.941\n",
      "INFO:tensorflow:loss = 0.19328612, step = 2600 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.835\n",
      "INFO:tensorflow:loss = 0.20507392, step = 2700 (0.252 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2797 vs previous value: 2797. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 383.109\n",
      "INFO:tensorflow:loss = 0.124491625, step = 2800 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.968\n",
      "INFO:tensorflow:loss = 0.17685789, step = 2900 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.917\n",
      "INFO:tensorflow:loss = 0.15273555, step = 3000 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.493\n",
      "INFO:tensorflow:loss = 0.13914631, step = 3100 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.813\n",
      "INFO:tensorflow:loss = 0.1307392, step = 3200 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.052\n",
      "INFO:tensorflow:loss = 0.17918961, step = 3300 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.705\n",
      "INFO:tensorflow:loss = 0.17099018, step = 3400 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.918\n",
      "INFO:tensorflow:loss = 0.13603519, step = 3500 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.1\n",
      "INFO:tensorflow:loss = 0.122351706, step = 3600 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.065\n",
      "INFO:tensorflow:loss = 0.122214176, step = 3700 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.126\n",
      "INFO:tensorflow:loss = 0.23321684, step = 3800 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.607\n",
      "INFO:tensorflow:loss = 0.16034988, step = 3900 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.617\n",
      "INFO:tensorflow:loss = 0.15581909, step = 4000 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.061\n",
      "INFO:tensorflow:loss = 0.12243191, step = 4100 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.953\n",
      "INFO:tensorflow:loss = 0.12813458, step = 4200 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.121\n",
      "INFO:tensorflow:loss = 0.12848443, step = 4300 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.307\n",
      "INFO:tensorflow:loss = 0.16487713, step = 4400 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.798\n",
      "INFO:tensorflow:loss = 0.16748402, step = 4500 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.725\n",
      "INFO:tensorflow:loss = 0.104549065, step = 4600 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.943\n",
      "INFO:tensorflow:loss = 0.17655256, step = 4700 (0.255 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4702 vs previous value: 4702. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 369.179\n",
      "INFO:tensorflow:loss = 0.10025891, step = 4800 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.386\n",
      "INFO:tensorflow:loss = 0.11928501, step = 4900 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.606\n",
      "INFO:tensorflow:loss = 0.11499535, step = 5000 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.371\n",
      "INFO:tensorflow:loss = 0.21441577, step = 5100 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.993\n",
      "INFO:tensorflow:loss = 0.16192858, step = 5200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.693\n",
      "INFO:tensorflow:loss = 0.11077397, step = 5300 (0.291 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5400...\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into /tmp/tmp505sf4re/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5400...\n",
      "INFO:tensorflow:Loss for final step: 0.07298125.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-06T00:56:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp505sf4re/model.ckpt-5400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.47464s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-06-00:56:45\n",
      "INFO:tensorflow:Saving dict for global step 5400: accuracy = 0.95, global_step = 5400, loss = 0.1640217\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5400: /tmp/tmp505sf4re/model.ckpt-5400\n",
      "{'accuracy': 0.95, 'loss': 0.1640217, 'global_step': 5400}\n"
     ]
    }
   ],
   "source": [
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
