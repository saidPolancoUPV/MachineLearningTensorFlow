{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_feature_columns_layers(data_df, categorical_cols, numeric_cols):\n",
    "    feature_columns = []\n",
    "    feature_layer_inputs = {}\n",
    "    \n",
    "    for feature_name in numeric_cols:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name)\n",
    "        \n",
    "    for feature_name in categorical_cols:\n",
    "        vocabulary = data_df[feature_name].unique()\n",
    "        cat = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "        cat_one_hot = tf.feature_column.indicator_column(cat)\n",
    "        feature_columns.append(cat_one_hot)\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name, dtype=tf.int32)\n",
    "        \n",
    "    return feature_columns, feature_layer_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactions(interactions_list, buckets=5):\n",
    "    feature_columns = []\n",
    "    \n",
    "    for (a, b) in interactions_list:\n",
    "        crossed_feature = tf.feature_column.crossed_column([a, b], hash_bucket_size=buckets)\n",
    "        crossed_feature_one_hot = tf.feature_column.indicator_column(crossed_feature)\n",
    "        feature_columns.append(crossed_feature_one_hot)\n",
    "        \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linreg(feature_columns, feature_layer_inputs, optimizer):\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, kernel_initializer='normal', activation='linear')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "path = tf.keras.utils.get_file(housing_url.split(\"/\")[-1], housing_url)\n",
    "\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',\n",
    "           'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_table(path, delim_whitespace=True, header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "interactions_columns = create_interactions([['RM', 'LSTAT']])\n",
    "\n",
    "feature_columns += interactions_columns\n",
    "\n",
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model = create_linreg(feature_columns, feature_layer_inputs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp4xua2uha', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "def canned_keras(model):\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    keras_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=model_dir)\n",
    "    return keras_estimator\n",
    "\n",
    "estimator = canned_keras(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=256):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "train = data.sample(frac=0.8).copy()\n",
    "y_train = train['MEDV']\n",
    "train.drop('MEDV', axis=1, inplace=True)\n",
    "\n",
    "test= data.loc[~data.index.isin(train.index)].copy()\n",
    "y_test = test['MEDV']\n",
    "test.drop('MEDV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4xua2uha/model.ckpt-2800\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2800...\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into /tmp/tmp4xua2uha/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2800...\n",
      "INFO:tensorflow:loss = 25.710728, step = 2800\n",
      "INFO:tensorflow:global_step/sec: 145.93\n",
      "INFO:tensorflow:loss = 22.670687, step = 2900 (0.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.478\n",
      "INFO:tensorflow:loss = 20.927778, step = 3000 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.222\n",
      "INFO:tensorflow:loss = 23.12601, step = 3100 (0.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.308\n",
      "INFO:tensorflow:loss = 21.791676, step = 3200 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.656\n",
      "INFO:tensorflow:loss = 20.629124, step = 3300 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.309\n",
      "INFO:tensorflow:loss = 25.686096, step = 3400 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.461\n",
      "INFO:tensorflow:loss = 17.1195, step = 3500 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.321\n",
      "INFO:tensorflow:loss = 23.867409, step = 3600 (0.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.37\n",
      "INFO:tensorflow:loss = 25.593353, step = 3700 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.642\n",
      "INFO:tensorflow:loss = 18.43347, step = 3800 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.893\n",
      "INFO:tensorflow:loss = 21.969648, step = 3900 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.939\n",
      "INFO:tensorflow:loss = 19.618982, step = 4000 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.168\n",
      "INFO:tensorflow:loss = 21.50027, step = 4100 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.315\n",
      "INFO:tensorflow:loss = 22.203476, step = 4200 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.016\n",
      "INFO:tensorflow:loss = 23.218513, step = 4300 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.965\n",
      "INFO:tensorflow:loss = 19.660791, step = 4400 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.197\n",
      "INFO:tensorflow:loss = 19.355785, step = 4500 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.745\n",
      "INFO:tensorflow:loss = 22.328115, step = 4600 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.231\n",
      "INFO:tensorflow:loss = 22.527245, step = 4700 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.755\n",
      "INFO:tensorflow:loss = 20.953342, step = 4800 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.651\n",
      "INFO:tensorflow:loss = 22.047337, step = 4900 (0.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.469\n",
      "INFO:tensorflow:loss = 20.074585, step = 5000 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.333\n",
      "INFO:tensorflow:loss = 20.018341, step = 5100 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.085\n",
      "INFO:tensorflow:loss = 24.921818, step = 5200 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.089\n",
      "INFO:tensorflow:loss = 24.253117, step = 5300 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.513\n",
      "INFO:tensorflow:loss = 21.833258, step = 5400 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.642\n",
      "INFO:tensorflow:loss = 18.921528, step = 5500 (0.664 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5600...\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into /tmp/tmp4xua2uha/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5600...\n",
      "INFO:tensorflow:Loss for final step: 17.803995.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-04T16:14:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4xua2uha/model.ckpt-5600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16054s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-04-16:14:28\n",
      "INFO:tensorflow:Saving dict for global step 5600: global_step = 5600, loss = 23.428205\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5600: /tmp/tmp4xua2uha/model.ckpt-5600\n",
      "{'loss': 23.428205, 'global_step': 5600}\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.82753277]\n",
      " [-0.9197132 ]\n",
      " [ 0.9121166 ]\n",
      " [ 0.8751093 ]\n",
      " [ 0.93666166]\n",
      " [-1.3062418 ]\n",
      " [-0.6605524 ]\n",
      " [-1.4155335 ]\n",
      " [ 0.858231  ]\n",
      " [-0.8840785 ]\n",
      " [ 0.87800807]\n",
      " [-0.9012212 ]\n",
      " [-0.90697014]\n",
      " [-0.8478116 ]\n",
      " [-0.9612655 ]\n",
      " [-0.9268641 ]\n",
      " [-0.8637465 ]\n",
      " [ 0.8671663 ]\n",
      " [-0.8810288 ]\n",
      " [-0.888186  ]\n",
      " [ 0.85306275]\n",
      " [ 0.9141941 ]\n",
      " [-0.9207836 ]\n",
      " [ 0.83163726]\n",
      " [ 1.3425697 ]\n",
      " [-0.7727633 ]\n",
      " [-0.86899364]]\n"
     ]
    }
   ],
   "source": [
    "weights = estimator.get_variable_value('layer_with_weights-1/kernel/.ATTRIBUTES/VARIABLE_VALUE')\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(feature_columns):\n",
    "    labels = list()\n",
    "    \n",
    "    for col in feature_columns:\n",
    "        col_config = col.get_config()\n",
    "        if 'key' in col_config:\n",
    "            labels.append(col_config['key'])\n",
    "        elif 'categorical_column' in col_config:\n",
    "            if col_config['categorical_column']['class_name'] == 'VocabolaryListCategoricalColumn':\n",
    "                key = col_config['categorical_column']['config']['key']\n",
    "                for item in col_config['categorical_column']['config']['vocabulary_list']:\n",
    "                    labels.append(key+'_val='+str(item))\n",
    "            elif col_config['categorical_column']['class_name'] == 'CrossedColumn':\n",
    "                keys = col_config['categorical_column']['config']['keys']\n",
    "                for bucket in range(col_config['categorical_column']['config']['hash_bucket_size']):\n",
    "                    labels.append('x'.join(keys)+'_bkt_'+str(bucket))\n",
    "                    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM            : -0.83\n",
      "ZN              : -0.92\n",
      "INDUS           : +0.91\n",
      "NOX             : +0.88\n",
      "RM              : +0.94\n",
      "AGE             : -1.31\n",
      "DIS             : -0.66\n",
      "TAX             : -1.42\n",
      "PTRATIO         : +0.86\n",
      "B               : -0.88\n",
      "LSTAT           : +0.88\n",
      "RMxLSTAT_bkt_0  : -0.90\n",
      "RMxLSTAT_bkt_1  : -0.91\n",
      "RMxLSTAT_bkt_2  : -0.85\n",
      "RMxLSTAT_bkt_3  : -0.96\n",
      "RMxLSTAT_bkt_4  : -0.93\n"
     ]
    }
   ],
   "source": [
    "labels = extract_labels(feature_columns)\n",
    "\n",
    "for label, weight in zip(labels, weights):\n",
    "    print(f\"{label:15s} : {weight[0]:+.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
