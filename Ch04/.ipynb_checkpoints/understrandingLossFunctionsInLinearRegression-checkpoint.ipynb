{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linreg(feature_columns, feature_layer_inputs, optimizer,\n",
    "                  loss='mean_squared_error', metrics=['mean_absolute_error']):\n",
    "    feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "    outputs = keras.layers.Dense(1, kernel_initializer='normal', activation='linear')(norm)\n",
    "    \n",
    "    model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_feature_columns_layers(data_df, categorical_cols, numeric_cols):\n",
    "    feature_columns = []\n",
    "    feature_layer_inputs = {}\n",
    "    \n",
    "    for feature_name in numeric_cols:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name)\n",
    "        \n",
    "    for feature_name in categorical_cols:\n",
    "        vocabulary = data_df[feature_name].unique()\n",
    "        cat = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "        cat_one_hot = tf.feature_column.indicator_column(cat)\n",
    "        feature_columns.append(cat_one_hot)\n",
    "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name, dtype=tf.int32)\n",
    "        \n",
    "    return feature_columns, feature_layer_inputs\n",
    "\n",
    "learning_rate = 0.5\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=256):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "def create_interactions(interactions_list, buckets=5):\n",
    "    feature_columns = []\n",
    "    \n",
    "    for (a, b) in interactions_list:\n",
    "        crossed_feature = tf.feature_column.crossed_column([a, b], hash_bucket_size=buckets)\n",
    "        crossed_feature_one_hot = tf.feature_column.indicator_column(crossed_feature)\n",
    "        feature_columns.append(crossed_feature_one_hot)\n",
    "        \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n",
      "49152/49082 [==============================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "housing_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "path = tf.keras.utils.get_file(housing_url.split(\"/\")[-1], housing_url)\n",
    "\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',\n",
    "           'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_table(path, delim_whitespace=True, header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns, feature_layer_inputs = define_feature_columns_layers(data, categorical_cols, numeric_cols)\n",
    "interactions_columns = create_interactions([['RM', 'LSTAT']])\n",
    "\n",
    "feature_columns += interactions_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def canned_keras(model):\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    keras_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=model_dir)\n",
    "    return keras_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpa76cm84i', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Ftrl(learning_rate=0.2)\n",
    "model = create_linreg(feature_columns, feature_layer_inputs, optimizer,\n",
    "                      loss='mean_absolute_error',\n",
    "                     metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "\n",
    "estimator = canned_keras(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "train = data.sample(frac=0.8).copy()\n",
    "y_train = train['MEDV']\n",
    "train.drop('MEDV', axis=1, inplace=True)\n",
    "\n",
    "test= data.loc[~data.index.isin(train.index)].copy()\n",
    "y_test = test['MEDV']\n",
    "test.drop('MEDV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmpa76cm84i/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: /tmp/tmpa76cm84i/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpa76cm84i/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 22.952736, step = 0\n",
      "INFO:tensorflow:global_step/sec: 137.395\n",
      "INFO:tensorflow:loss = 3.096592, step = 100 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.713\n",
      "INFO:tensorflow:loss = 3.133734, step = 200 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.428\n",
      "INFO:tensorflow:loss = 3.052707, step = 300 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.194\n",
      "INFO:tensorflow:loss = 3.013544, step = 400 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.836\n",
      "INFO:tensorflow:loss = 3.0001643, step = 500 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.656\n",
      "INFO:tensorflow:loss = 3.1159813, step = 600 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.775\n",
      "INFO:tensorflow:loss = 3.00914, step = 700 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.869\n",
      "INFO:tensorflow:loss = 2.9755607, step = 800 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.449\n",
      "INFO:tensorflow:loss = 3.225439, step = 900 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.966\n",
      "INFO:tensorflow:loss = 2.8319144, step = 1000 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.041\n",
      "INFO:tensorflow:loss = 3.095672, step = 1100 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.048\n",
      "INFO:tensorflow:loss = 3.2112901, step = 1200 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.37\n",
      "INFO:tensorflow:loss = 2.7495532, step = 1300 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.322\n",
      "INFO:tensorflow:loss = 2.9305592, step = 1400 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.679\n",
      "INFO:tensorflow:loss = 3.1309326, step = 1500 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.403\n",
      "INFO:tensorflow:loss = 2.9994678, step = 1600 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.064\n",
      "INFO:tensorflow:loss = 2.8800418, step = 1700 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.713\n",
      "INFO:tensorflow:loss = 3.2487135, step = 1800 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.719\n",
      "INFO:tensorflow:loss = 3.068005, step = 1900 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.466\n",
      "INFO:tensorflow:loss = 2.965974, step = 2000 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.511\n",
      "INFO:tensorflow:loss = 3.2541862, step = 2100 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.978\n",
      "INFO:tensorflow:loss = 3.0588794, step = 2200 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.323\n",
      "INFO:tensorflow:loss = 2.8611898, step = 2300 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.394\n",
      "INFO:tensorflow:loss = 2.8161402, step = 2400 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.621\n",
      "INFO:tensorflow:loss = 3.0190134, step = 2500 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.893\n",
      "INFO:tensorflow:loss = 2.9531963, step = 2600 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.431\n",
      "INFO:tensorflow:loss = 3.0869994, step = 2700 (0.665 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2800...\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into /tmp/tmpa76cm84i/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2800...\n",
      "INFO:tensorflow:Loss for final step: 2.8661983.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T13:52:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpa76cm84i/model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.17212s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-13:52:44\n",
      "INFO:tensorflow:Saving dict for global step 2800: global_step = 2800, loss = 3.017049, mean_absolute_error = 3.017049, mean_squared_error = 25.819746\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: /tmp/tmpa76cm84i/model.ckpt-2800\n",
      "{'loss': 3.017049, 'mean_absolute_error': 3.017049, 'mean_squared_error': 25.819746, 'global_step': 2800}\n"
     ]
    }
   ],
   "source": [
    "estimator.train(train_input_fn)\n",
    "result = estimator.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
